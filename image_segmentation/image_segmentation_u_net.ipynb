{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comments about Assignment 2\n",
    "#### Adriano Mundo 10524163 , Mario Sacaj 10521887\n",
    "\n",
    "Assignment 2 for the ANN2DL course was to participate a competition on kaggle with the objective to develop a Neural Network Architecture for Image Segmentation.\n",
    "\n",
    "We initially tried to adapt the CNN Segmentation model presented in the Lab: we set the random SEED, used the \"validation_split\" attribute in order to automatically generate the validation data, we applied some data augumentation, we set the loss to \"binary crossentropy\" as we thought it suited more the classification problem we had and adapted the model structure so as to output only one value for pixel in the [0,1] range. \n",
    "It however performed poorly. So, after searching a bit through the Internet we found a Segmentation classificator called **MultiResUNet**, in which **UNet**'s skip connections were replaced with *Res* paths.\n",
    "\n",
    "Paper: https://arxiv.org/pdf/1902.04049.pdf\n",
    "\n",
    "Proposed implementation: https://github.com/nibtehaz/MultiResUNet\n",
    "\n",
    "We adapted the proposed implementation to our domain and we in fact experienced a jump in *val_My_IoU* score (it went from 20 something % to 55 %, achieved in just one epoch). It however stuck at that value and then started to decay as the epochs were passing. Fine tuning hyperparameters like the learnig rate or the optimizer didn't help.\n",
    "So we changed again our structure to a classic **UNet** model, adapting the implementation proposed here:\n",
    "\n",
    "https://github.com/zhixuhao/unet\n",
    "\n",
    "It converged more slowly than MultiResUNet but outperformed it. Finetuning the data augumentation parameters and letting it train for 40 epochs allowed us to achieve a even better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from datetime import datetime\n",
    "import json\n",
    "\n",
    "# Set the seed for random operations. \n",
    "# This let our experiments to be reproducible. \n",
    "SEED = 1234\n",
    "tf.random.set_seed(SEED)  \n",
    "\n",
    "# Set Dataset dir\n",
    "dataset_dir = '/kaggle/input/ann-and-dl-image-segmentation/Segmentation_Dataset'\n",
    "\n",
    "# If you want to load your model from disk set True\n",
    "restore_model = False\n",
    "\n",
    "# If you want to commit set to False\n",
    "not_commit = True\n",
    "\n",
    "# Get current working directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "# Set GPU memory growth\n",
    "# Allows to only as much GPU memory as needed\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "  try:\n",
    "    # Currently, memory growth needs to be the same across GPUs\n",
    "    for gpu in gpus:\n",
    "      tf.config.experimental.set_memory_growth(gpu, True)\n",
    "    logical_gpus = tf.config.experimental.list_logical_devices('GPU')\n",
    "    print(len(gpus), \"Physical GPUs,\", len(logical_gpus), \"Logical GPUs\")\n",
    "  except RuntimeError as e:\n",
    "    # Memory growth must be set before GPUs have been initialized\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# SPECIFIC PARAMETERS\n",
    "\n",
    "# Batch size\n",
    "bs = 4\n",
    "\n",
    "# img shape\n",
    "img_h = 256\n",
    "img_w = 256\n",
    "\n",
    "# clsses 0,1 building and background\n",
    "num_classes=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â IMAGE GENERATOR CREATION WITH DATA AUGUMENTATION\n",
    "\n",
    "apply_data_augmentation = True\n",
    "\n",
    "# Create training ImageDataGenerator object\n",
    "# We need two different generators for images and corresponding masks\n",
    "if apply_data_augmentation:\n",
    "    \n",
    "    train_img_data_gen = ImageDataGenerator(rotation_range=10,\n",
    "                                            width_shift_range=10,\n",
    "                                            height_shift_range=10,\n",
    "                                            zoom_range=0.3,\n",
    "                                            horizontal_flip=True,\n",
    "                                            vertical_flip=True,\n",
    "                                            fill_mode='constant',\n",
    "                                            cval=0,\n",
    "                                            rescale=1./255,\n",
    "                                           validation_split = 0.2)\n",
    "    \n",
    "    train_mask_data_gen = ImageDataGenerator(rotation_range=10,\n",
    "                                             width_shift_range=10,\n",
    "                                             height_shift_range=10,\n",
    "                                             zoom_range=0.3,\n",
    "                                             horizontal_flip=True,\n",
    "                                             vertical_flip=True,\n",
    "                                             fill_mode='constant',\n",
    "                                             cval=0,\n",
    "                                            rescale=1./255,\n",
    "                                            validation_split = 0.2)\n",
    "else:\n",
    "    \n",
    "    train_img_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "    train_mask_data_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Create test ImageDataGenerator object\n",
    "test_img_data_gen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMG DATA GENERATOR FLOW FROM DIRECTORY\n",
    "\n",
    "# Training\n",
    "# Two different generators for images and masks\n",
    "# Same SEED to train and validation generator\n",
    "training_dir = os.path.join(dataset_dir, 'training')\n",
    "\n",
    "train_img_gen = train_img_data_gen.flow_from_directory(os.path.join(training_dir, 'images'),\n",
    "                                                       target_size=(img_h, img_w),\n",
    "                                                       batch_size=bs,\n",
    "                                                       color_mode='rgb',\n",
    "                                                       class_mode=None,\n",
    "                                                       shuffle=True,\n",
    "                                                       interpolation='bilinear',\n",
    "                                                       seed=SEED,\n",
    "                                                       subset='training')  \n",
    "\n",
    "train_mask_gen = train_mask_data_gen.flow_from_directory(os.path.join(training_dir, 'masks'),\n",
    "                                                         target_size=(img_h, img_w),\n",
    "                                                         batch_size=bs,\n",
    "                                                         color_mode='grayscale',\n",
    "                                                         class_mode=None,\n",
    "                                                         shuffle=True,\n",
    "                                                         interpolation='bilinear',\n",
    "                                                         seed=SEED,\n",
    "                                                        subset='training')\n",
    "\n",
    "train_gen = zip(train_img_gen, train_mask_gen)\n",
    "\n",
    "# Validation \n",
    "valid_img_gen = train_img_data_gen.flow_from_directory(os.path.join(training_dir, 'images'),\n",
    "                                                       target_size=(img_h, img_w),\n",
    "                                                       batch_size=bs,\n",
    "                                                       color_mode='rgb',\n",
    "                                                       class_mode=None, \n",
    "                                                       shuffle=False,\n",
    "                                                       interpolation='bilinear',\n",
    "                                                       seed=SEED,\n",
    "                                                       subset='validation')\n",
    "\n",
    "valid_mask_gen = train_mask_data_gen.flow_from_directory(os.path.join(training_dir, 'masks'),\n",
    "                                                         target_size=(img_h, img_w),\n",
    "                                                         batch_size=bs,\n",
    "                                                         color_mode='grayscale',\n",
    "                                                         class_mode=None, \n",
    "                                                         shuffle=False,\n",
    "                                                         interpolation='bilinear',\n",
    "                                                         seed=SEED,\n",
    "                                                         subset='validation')\n",
    "\n",
    "valid_gen = zip(valid_img_gen, valid_mask_gen)\n",
    "\n",
    "# Test\n",
    "test_dir = os.path.join(dataset_dir, 'test')\n",
    "\n",
    "test_img_gen = test_img_data_gen.flow_from_directory(os.path.join(test_dir, 'images'),\n",
    "                                                     target_size=(img_h, img_w),\n",
    "                                                     batch_size=bs,\n",
    "                                                     color_mode='rgb',\n",
    "                                                     class_mode=None, \n",
    "                                                     shuffle=False,\n",
    "                                                     interpolation='bilinear',\n",
    "                                                     seed=SEED)\n",
    "\n",
    "test_gen = test_img_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UTILS FUNCTIONS\n",
    "\n",
    "# Casting float values to int \n",
    "def prepare_target(x_, y_):\n",
    "    y_ = tf.cast(y_, tf.int32)\n",
    "    return x_, y_\n",
    "\n",
    "# Evaluation Metric\n",
    "def my_IoU(y_true, y_pred):\n",
    "    \n",
    "    # from pobability to predicted class {0, 1}\n",
    "    y_pred = tf.cast(y_pred > 0.5, tf.float32) # when using sigmoid. Use argmax for softmax\n",
    "\n",
    "    # A and B\n",
    "    intersection = tf.reduce_sum(y_true * y_pred)\n",
    "    \n",
    "    # A or B\n",
    "    union = tf.reduce_sum(y_true) + tf.reduce_sum(y_pred) - intersection\n",
    "    \n",
    "    # IoU\n",
    "    return intersection / union\n",
    "\n",
    "# Save the model's weights\n",
    "def saveModel(model):\n",
    "\n",
    "    model_json = model.to_json()\n",
    "    \n",
    "    fp = open('modelP.json','w')\n",
    "    fp.write(model_json)\n",
    "    \n",
    "    model.save_weights('modelW.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATASET OBJECT CREATION AND REPEAT\n",
    "\n",
    "# Training\n",
    "train_dataset = tf.data.Dataset.from_generator(lambda: train_gen,\n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, img_h, img_w, 1]))\n",
    "\n",
    "train_dataset = train_dataset.map(prepare_target)\n",
    "\n",
    "train_dataset = train_dataset.repeat()\n",
    "\n",
    "# Validation\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: valid_gen, \n",
    "                                               output_types=(tf.float32, tf.float32),\n",
    "                                               output_shapes=([None, img_h, img_w, 3], [None, img_h, img_w, 1]))\n",
    "\n",
    "valid_dataset = valid_dataset.map(prepare_target)\n",
    "\n",
    "valid_dataset = valid_dataset.repeat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â HYPERPARAMETERS\n",
    "\n",
    "# Loss\n",
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=False) \n",
    "\n",
    "# Learning rate\n",
    "lr = 1e-3\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate = lr)\n",
    "\n",
    "# Validation metrics\n",
    "metrics = [my_IoU]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage.io as io\n",
    "import skimage.transform as trans\n",
    "import numpy as np\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "\n",
    "\n",
    "def unet(metrics, input_size = (256,256,3)):\n",
    "\n",
    "    ##ENCODER\n",
    "    inputs = Input(input_size)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n",
    "    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "\n",
    "    ## DECODER\n",
    "    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(1, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(input = inputs, output = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'binary_crossentropy', metrics = metrics)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL INSTANCE\n",
    "\n",
    "modelUnet = unet(metrics)\n",
    "\n",
    "# MODEL COMPILING -> UNET is already compiled\n",
    "#model.compile(optimizer=optimizer, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CALLBACKS\n",
    "cwd = os.getcwd()\n",
    "\n",
    "exps_dir = os.path.join(cwd, 'segmentation_experiments')\n",
    "if not os.path.exists(exps_dir):\n",
    "    os.makedirs(exps_dir)\n",
    "\n",
    "now = datetime.now().strftime('%b%d_%H-%M-%S')\n",
    "\n",
    "model_name = 'CNN'\n",
    "\n",
    "exp_dir = os.path.join(exps_dir, model_name + '_' + str(now))\n",
    "if not os.path.exists(exp_dir):\n",
    "    os.makedirs(exp_dir)\n",
    "    \n",
    "callbacks = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EARLY STOPPING\n",
    "early_stop = False\n",
    "if early_stop:\n",
    "    es_callback = tf.keras.callback.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "    callbacks.append(es_callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL TRAINING\n",
    "        \n",
    "modelUnet.fit_generator(train_gen,\n",
    "            epochs=40,  #### set repeat in training dataset\n",
    "            steps_per_epoch=len(train_img_gen),\n",
    "            validation_data=valid_gen,\n",
    "            validation_steps=len(valid_img_gen), \n",
    "            callbacks=callbacks)\n",
    "\n",
    "saveModel(modelUnet)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODING OF OUTPUT FOR SUBMISSION\n",
    "def rle_encode(img):\n",
    "      # Flatten column-wise\n",
    "      pixels = img.T.flatten()\n",
    "      pixels = np.concatenate([[0], pixels, [0]])\n",
    "      runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "      runs[1::2] -= runs[::2]\n",
    "      return ' '.join(str(x) for x in runs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RESULTS FILE CREATION\n",
    "def create_csv(results, results_dir=''):\n",
    "\n",
    "    csv_fname = 'results_'\n",
    "    csv_fname += datetime.now().strftime('%b%d_%H-%M-%S') + '.csv'\n",
    "\n",
    "    with open(csv_fname, 'w') as f:\n",
    "\n",
    "      f.write('ImageId,EncodedPixels,Width,Height\\n')\n",
    "\n",
    "      for key, value in results.items():\n",
    "          f.write(key + ',' + str(value) + ',' + '256' + ',' + '256' + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMPETITION SCORE \n",
    "def competition_score(y_true, y_pred):\n",
    "    score = my_IoU(y_true, y_pred)\n",
    "    thresholds = np.arange(0.5, 1.0, 0.05)\n",
    "    competition_score = 0\n",
    "\n",
    "    for t in thresholds:\n",
    "        if score > t:\n",
    "            competition_score += 1\n",
    "\n",
    "    competition_score /= len(thresholds)\n",
    "\n",
    "    return competition_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test(x_):\n",
    "    y_ = tf.cast(x_ > 0.5, tf.int32)\n",
    "    return y_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not_commit:  \n",
    "    preds = modelUnet.predict_generator(test_gen)\n",
    "    preds = prepare_test(preds)\n",
    "    preds = np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE CSV \n",
    "image_filenames = test_gen.filenames\n",
    "image_filenames\n",
    "results = {}\n",
    "if not_commit:\n",
    "    for i in range(len(image_filenames)):\n",
    "       results[(image_filenames[i][4:-4])] = rle_encode(preds[i])\n",
    "\n",
    "    create_csv(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
